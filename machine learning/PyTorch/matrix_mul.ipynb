{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e640576f",
   "metadata": {},
   "source": [
    "### Matrix multiplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dbc7baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02907446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals :  {tensor([1, 4, 9])}\n"
     ]
    }
   ],
   "source": [
    "# Element wise \n",
    "tensor = torch.tensor([1,2,3])\n",
    "print(tensor, '*', tensor)\n",
    "print(f\"Equals : \", {tensor * tensor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b1641e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor,tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5add00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"@\" --> Matrix multiplication\n",
    "tensor @ tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059fee6e",
   "metadata": {},
   "source": [
    "Two main rules for matrix multiplication\n",
    "\n",
    "1. The **inner dimnesions** must match : \n",
    "* (3,2) @ (3,2) ---> won't work\n",
    "* (3,2) @ (2,3) ---> will work\n",
    "* (2,3) @ (3,2) ---> will work\n",
    "\n",
    "2. The resulting matrix has the shape of the **outer dimensions**\n",
    "* (2,3) @ (3,2) ---> (2,2)\n",
    "* (3,2) @ (2,3) ---> (3,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eec755a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3616, 0.7436],\n",
       "        [0.4585, 1.1968]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul = torch.matmul(torch.rand(2,5), torch.rand(5,2))\n",
    "mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a684da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31dee04",
   "metadata": {},
   "source": [
    "## Transpose\n",
    "To fix the tensor shape issue, we can multiply the shape of one of our tensors using a **transpose**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c5ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_A = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "tensor_B = torch.tensor([[7,10],[8,11],[9,12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d2fccde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7, 10],\n",
       "         [ 8, 11],\n",
       "         [ 9, 12]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B, tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a34d511e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8,  9],\n",
       "         [10, 11, 12]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc70e7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor_A,tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ca176e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor_A,tensor_B.T).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe41a3",
   "metadata": {},
   "source": [
    "Finding the min,max,mean,sum(Tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83278c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0,100,10)\n",
    "x, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3dff4552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum\n",
    "torch.sum(x),x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "072c778b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the max\n",
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "050752e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the max\n",
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08d80170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean \n",
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()\n",
    "# NOTE - the torch.mean() function requires a tensor of float32 datatype to work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bdb41e",
   "metadata": {},
   "source": [
    "Finding the positional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925edab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the minimum value with argmin() --> returns index position of target tensor where the minimum value occurs\n",
    "x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "255cc02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the maximum value with argmax()\n",
    "x.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7463ce99",
   "metadata": {},
   "source": [
    "Reshaping, stacking, squeezing, unsqueezing tensors\n",
    "\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - Shares the same memory as the original tensor, shows the same tensor for a different perspective\n",
    "* Stacking - Combining multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "* Squeeze - removes all '1' dimensions from a tensor \n",
    "* Unsqueeze - add a '1' dimension to a target tensor \n",
    "* Permute - Returns a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb8a83e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1.,10.)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8336cfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add extra dimension \n",
    "x_reshaped = x.reshape(1,9)\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27e583e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = x.view(1,9)\n",
    "z, z.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c53e6e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x as they share the same memory as the original    \n",
    "z[:,0] = 5\n",
    "z,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b54f5123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x,x,x,x],dim = 0)\n",
    "x_stacked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eef1ed47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.squeeze() - removes all single dimension from a target tensor\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bd61de6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f111826a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3c1fdd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cf6174d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor : tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Previous tensor shape : torch.Size([1, 9])\n",
      "\n",
      "New tensor : tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "New tensor shape : torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor : {x_reshaped}\")\n",
    "print(f\"Previous tensor shape : {x_reshaped.shape}\")\n",
    "# Removes extra dimension from x_shaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor : {x_squeezed}\")\n",
    "print(f\"New tensor shape : {x_squeezed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a606f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous target : tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Previous shape : torch.Size([9])\n",
      "\n",
      "New tensor : [x.unsqueezed]\n",
      "New tensor shape : [x.unsqueezed.shape]\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze() - adds a single dimension from a target tensor at a specific dimension\n",
    "print(f\"Previous target : {x_squeezed}\")\n",
    "print(f\"Previous shape : {x_squeezed.shape}\")\n",
    "\n",
    "# Adds an extra dimension with unsqueezed \n",
    "x_unsqueesed = x_squeezed.unsqueeze(dim = 0)\n",
    "print(f\"\\nNew tensor : [x.unsqueezed]\")\n",
    "print(f\"New tensor shape : [x.unsqueezed.shape]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c8c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pervious shape : torch.Size([224, 224, 3])\n",
      "New shape : torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute --> rearranges the dimensions of a target tensor in a specified order \n",
    "x_original = torch.rand(size = (224,224,3)) #[height, width, color_channels]\n",
    "\n",
    "# permute the original tensor to rearrange the axis (or dimension) order\n",
    "x_permuted = x_original.permute(2,0,1)  # Shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Pervious shape : {x_original.shape}\")\n",
    "print(f\"New shape : {x_permuted.shape}\") #[color_channels, height, width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bed561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
